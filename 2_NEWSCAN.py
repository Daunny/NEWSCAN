import streamlit as st
import numpy as np
from numpy import dot
from numpy.linalg import norm
import time
import pandas as pd
import matplotlib.pyplot as plt
import platform
import matplotlib.font_manager as fm
import plotly.express as px
from datetime import datetime
import functools
from wordcloud import WordCloud
from annotated_text import annotated_text


# ë¬¸ì¥ ê°„ì˜ ìœ ì‚¬ì„± ë¶„ì„ì„ ìœ„í•œ ëª¨ë“ˆ
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from st_aggrid import GridOptionsBuilder, AgGrid, GridUpdateMode, ColumnsAutoSizeMode

import warnings
warnings.simplefilter("ignore")


# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title='NewScan',
    page_icon=':newspaper:',
    layout='wide'
)

# í•œê¸€ í°íŠ¸ ì§€ì •
from matplotlib import font_manager, rc
plt.rcParams['axes.unicode_minus'] = False

if platform.system() == 'Darwin':  # ë§¥OS
    rc('font', family='AppleGothic')
elif platform.system() == 'Windows':  # ìœˆë„ìš°
    path = "c:/Windows/Fonts/malgun.ttf"
    font_name = font_manager.FontProperties(fname=path).get_name()
    rc('font', family=font_name)
else:
    print('Unknown system...  sorry~~~')

# í•œê¸€í°íŠ¸ì§€ì • 2

fontprop = fm.FontProperties(fname="font/NanumGothic.ttf")
chart = functools.partial(st.plotly_chart, use_container_width=True)
COMMON_ARGS = {
    "color": "symbol",
    "color_discrete_sequence": px.colors.sequential.Greens,
    "hover_data": [
        "account_name",
        "percent_of_account",
        "quantity",
        "total_gain_loss_dollar",
        "total_gain_loss_percent",
    ],
}

####
# ë¬¸ì¥ ìœ ì‚¬ë„ ì‚°ì¶œì„ ìœ„í•œ cosine ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
def cos_sim(A, B):
    return dot(A, B) / (norm(A) * norm(B))

# ì œëª© ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì´ìš©í•œ ìœ ì‚¬ ê¸°ì‚¬ ì¶”ì²œ
def get_recommendations(heads, cosine_sim, count=10):
    # ì„ íƒí•œ ê¸°ì‚¬ì˜ íƒ€ì´í‹€ë¡œë¶€í„° í•´ë‹¹ ê¸°ì‚¬ì˜ ì¸ë±ìŠ¤ë¥¼ ë°›ì•„ì˜¨ë‹¤.
    idx = title_to_index[heads]

    # í•´ë‹¹ ê¸°ì‚¬ì™€ ëª¨ë“  ê¸°ì‚¬ì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
    sim_scores = [i for i in enumerate(cosine_sim[idx])]

    # ìœ ì‚¬ë„ì— ë”°ë¼ ê¸°ì‚¬ë“¤ì„ ì •ë ¬í•œë‹¤.
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # ìœ ì‚¬ë„ê°€ 0.3 ì´ìƒì¸ ê¸°ì‚¬ë“¤ë§Œ ê°€ì ¸ì˜¨ë‹¤.
    sim_scores = [x for x in sim_scores if x[1] >= 0.3]

    # ê°€ì¥ ìœ ì‚¬í•œ 5ê°œì˜ ê¸°ì‚¬ë¥¼ ë°›ì•„ì˜¨ë‹¤.
    sim_scores = sim_scores[:count]

    # ê°€ì¥ ìœ ì‚¬í•œ 5ê°œì˜ ê¸°ì‚¬ì˜ ì¸ë±ìŠ¤ë¥¼ ì–»ëŠ”ë‹¤.
    news_indices = [idx[0] for idx in sim_scores]

    # ê°€ì¥ ìœ ì‚¬í•œ  5ê°œì˜ ê¸°ì‚¬ì˜ ì œëª©ì„ ë¦¬í„´í•œë‹¤.
    return [df['ì œëª©'].iloc[news_indices], sim_scores]


# ë°ì´í„°ì…‹ ì¤€ë¹„
@st.cache_data
def load_data():
    data = pd.read_csv('data/news_total.csv', index_col=0)
    return data
df = load_data()



####

# íƒ€ì´í‹€
st.title(":pager: NEWSANS")

# ë‰´ìŠ¤ ì¼ì í•„í„°ë§
st.subheader("ë‰´ìŠ¤ ì¼ì")
start_time = st.date_input(
    'Select date',
    value=(datetime(2023, 5, 21), datetime(2023, 5, 28))
)

# ì¼ì í•„í„°ë§
df = df[(df['ì¼ì'] >= str(start_time[0])) & (df['ì¼ì'] <= str(start_time[1]))]

#####
df2 = df[['ì¸ë¬¼', 'ìœ„ì¹˜', 'ê¸°ê´€']].fillna('')
df3 = df2.ì¸ë¬¼ + df2.ìœ„ì¹˜ + df2.ê¸°ê´€
# ë²¡í„°í™”
tfidf = TfidfVectorizer()
abc_tfidf_matrix = tfidf.fit_transform(df3)
k_men = sorted(tfidf.vocabulary_.items(), key=lambda x: x[1], reverse=True)
k_men = list(map(lambda x: x[0], k_men))


day_sel_i = str(start_time[0])
daily_data = df[df['ì¼ì'] == day_sel_i].reset_index()

y = start_time[0].year
m = start_time[0].month
d0 = start_time[0].day
d1 = start_time[1].day

st.write('---')

####

# ì˜µì…˜ ì„ íƒ 1,2
col01, col02, = st.columns(2)
# í‚¤ì›Œë“œ ê²€ìƒ‰
with col01:
    st.subheader("í‚¤ì›Œë“œ ê²€ìƒ‰")
    keyword_selections = st.multiselect(
    "Select í‚¤ì›Œë“œ to View", options = k_men, default = ['í˜„ëŒ€ì°¨'],
    label_visibility='collapsed',
    max_selections=1)

# ì–¸ë¡ ì‚¬ í•„í„°ë§
with col02:
    st.subheader("ì–¸ë¡ ì‚¬")
    accounts = list(df['ì–¸ë¡ ì‚¬'].unique())
    account_selections = st.multiselect(
    "Select ì–¸ë¡ ì‚¬ to View", options = accounts, default = ['ì¡°ì„ ì¼ë³´','ì¤‘ì•™ì¼ë³´','í•œê²¨ë ˆ','í•œêµ­ê²½ì œ','ë™ì•„ì¼ë³´', 'ë¨¸ë‹ˆíˆ¬ë°ì´'] ,
    label_visibility='collapsed')

st.write("---")

col11, col12, col13 = st.columns(3)

# ê°ì„± í•„í„°ë§
with col11:
    st.markdown(":moyai:**ê°ì„± í•„í„°ë§**")
    filling_selections = st.select_slider(
        "ê°ì • ë¶„ë¥˜",
        options=['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'],
        value=('ê¸ì •', 'ì¤‘ë¦½'),
        label_visibility='collapsed',
    )

# ë‰´ìŠ¤ ì œëª© - ë³¸ë¬¸ ì¼ì¹˜ë„ í•„í„°ë§
with col12:
    st.markdown(":question:**ì œëª©-ë³¸ë¬¸ ì¼ì¹˜ë„**")
    cosine_sim = st.slider(
        "0 : ë¶ˆì¼ì¹˜ -  1 : ì¼ì¹˜",
        min_value= 0.0,
        max_value= 1.0,
        value=(0.25, 0.75),
        step=0.01,
        label_visibility='collapsed',
    )

# ë‚šì‹œê¸°ì‚¬ í•„í„°ë§
with col13:
    st.markdown(":fishing_pole_and_fish: **ë‚šì‹œì„± ê¸°ì‚¬ í•„í„°ë§**")
    fishing = st.slider(
        "0 : ì˜ì‹¬  -  1 : ì‹ ë¢°",
        min_value= 0.0,
        max_value= 1.0,
        value=(0.25, 0.75),
        step=0.01,
        label_visibility='collapsed'
    )

st.write("---")
# ì–¸ë¡ ì‚¬ í•„í„°ë§
df = df[df['ì–¸ë¡ ì‚¬'].isin(account_selections)]
# í‚¤ì›Œë“œ í•„í„°ë§
df = df[df['í‚¤ì›Œë“œ'].str.contains(keyword_selections[0])]
# ê°ì„± í•„í„°ë§
df = df[df['Senti_label'].isin(filling_selections)]
# ë‰´ìŠ¤ ì œëª©-ë³¸ë¬¸ ì¼ì¹˜ë„ í•„í„°ë§
df = df[(df['Sim_score'] >= cosine_sim[0]) & (df['Sim_score'] <= cosine_sim[1])]
# ë‚šì‹œê¸°ì‚¬ í•„í„°ë§
df = df[(df['fishing_score'] >= fishing[0]) & (df['fishing_score'] <= fishing[1])]
df.sort_values(by='Sim_score', inplace=True, ascending=False)

####
def create_link(title, url: str) -> str:
    return f'''<a href="{url}">{title}</a>'''

# ë§í¬ìƒì„±
def summary_link(url: str) -> str:
    return f'''<a href="{url}">ğŸ“°</a>'''


# ê¸ì • ë¼ë²¨ ì´ëª¨ì§€
def senti_label(Senti_label) :
    if Senti_label == 'ê¸ì •':
        emoji = 'ğŸ”µ'
    elif Senti_label == 'ë¶€ì •':
        emoji = 'ğŸ”´'
    else:
        emoji = 'ğŸŸ¡'
    return emoji + Senti_label

# í”¼ì‹± ë¼ë²¨ ì´ëª¨ì§€
def fishing_label(fishing) :
    if fishing == 'ì–‘í˜¸':
        emoji2 = 'ì–‘í˜¸'
    else:
        emoji2 = 'ğŸŸí”¼ì‹±ì˜ì‹¬'
    return emoji2


df['ê¸°ì‚¬'] = [create_link(title, url) for title, url in zip(df['ì œëª©'], df['URL'])]
news = df[['ê¸°ì‚¬']].copy()

df['Link'] = [summary_link(url) for url in df["URL"]]
df['ê¸ë¶€ì • ì—¬ë¶€'] = df.Senti_label.map(lambda x: senti_label(x))
df['í”¼ì‹±ê¸°ì‚¬ ì—¬ë¶€'] = df['ë‚šì‹œê¸°ì‚¬'].map(lambda x: fishing_label(x))
df['ì œëª©-ë³¸ë¬¸ ì¼ì¹˜ë„(%)'] = df.Sim_score.map(lambda x: str(np.round(x*100,1))+'%')


### ë³¸ë¬¸

# ìµœì¢… ì¶œë ¥ ë°ì´í„°í”„ë ˆì„
n = 10

### êµ¬ë¶„

st.subheader(f':date:{y}ë…„ {m}ì›” {d0}ì¼ ~{m}ì›” {d1}ì¼ ')
st.markdown(f'**[ {keyword_selections[0]} ]** ê´€ë ¨ ê²½ì œ ê¸°ì‚¬ : **ì´ {len(df)}ê±´**')


###
col1, col2 = st.columns([0.4,0.6])

# ê¸ë¶€ì • ë¹„ìœ¨ pychart
with col1:
    st.markdown('')
    st.markdown(f'**ê¸ë¶€ì • ë¹„ìœ¨**')

    wedgeprops = {'width': 0.3, 'edgecolor': 'w', 'linewidth': 5}

    temp_df = pd.DataFrame(df['Senti_label'].value_counts())

    # colors = ['#ffc000', '#3e8df4', '#ff9999']
    color_map = {'ì¤‘ë¦½': '#ffc000', 'ê¸ì •': '#3e8df4', 'ë¶€ì •': '#ff9999'}
    temp_df["color"] = temp_df.index.map(color_map)
    colors = temp_df['color'].values
    wdges, labels, autopct = plt.pie(temp_df['Senti_label'], labels=temp_df.index, startangle=90,
                                     radius=1, autopct='%.1f%%', colors=colors, wedgeprops=wedgeprops,
                                     textprops={'font': fontprop}, pctdistance=1.2, labeldistance=1.4)

    plt.setp([labels, autopct], fontsize=15)
    plt.tight_layout()
    st.pyplot(plt)

# ì›Œë“œ í´ë¼ìš°ë“œ
with col2:
    st.markdown('')
    st.markdown(f'**ê´€ë ¨ í‚¤ì›Œë“œ**')
    st.caption('- ì–¸ê¸‰ëŸ‰ì€ í‚¤ì›Œë“œì˜ í¬ê¸°ì— ë¹„ë¡€í•¨')

    col_l, col_c, col_r = st.columns([0.05, 0.9, 0.05])

    with col_c:
        # ì¸ë¬¼, ìœ„ì¹˜, ê¸°ê´€ ì»¬ëŸ¼ ë‚´ ê²°ì¸¡ì¹˜ ë³€í™˜
        list = ['ì¸ë¬¼', 'ìœ„ì¹˜', 'ê¸°ê´€']
        for l in list:
            df[l].replace({np.nan: ''}, inplace=True)

        # í‚¤ì›Œë“œ ì»¬ëŸ¼ ë‚´ ì¤‘ë³µ í‚¤ì›Œë“œ ì œê±°
        for i in range(len(daily_data)):
            temp = ''
            for word in daily_data.iloc[i]['í‚¤ì›Œë“œ'].split(','):
                if word not in temp:
                    temp += word + ','
            df.at[i, 'í‚¤ì›Œë“œ'] = temp


        def word_count_dic(daily_data, col):
            cnt = {}
            for i in range(len(daily_data)):
                for word in daily_data.iloc[i][col].split(','):
                    if word in cnt:
                        cnt[word] += 1
                    else:
                        cnt[word] = 1
            del cnt['']
            return cnt
        # total_key = word_count_dic(daily_data, 'í‚¤ì›Œë“œ')
        # total_key = dict(sorted(total_key.items(), reverse=True, key=lambda x: x[1]))
        # people = word_count_dic(daily_data, 'ì¸ë¬¼')
        # location = word_count_dic(daily_data, 'ìœ„ì¹˜')
        # organization = word_count_dic(daily_data, 'ê¸°ê´€')

        people = df.ì¸ë¬¼.dropna()
        location = df.ìœ„ì¹˜.dropna()
        organization = df.ê¸°ê´€.dropna()
        etc = df.í‚¤ì›Œë“œ.dropna()

        # ë²¡í„°í™”
        tfidf = TfidfVectorizer(min_df=5, max_features=20)


        def tfidf_fit_trans(df):
            ab_tfidf_matrix = tfidf.fit_transform(df)
            key_dict = dict(sorted(tfidf.vocabulary_.items(), key=lambda x: x[1], reverse=True))
            return key_dict


        pp_keyword = tfidf_fit_trans(people)
        loc_keyword = tfidf_fit_trans(location)
        org_keyword = tfidf_fit_trans(organization)

        keyword_total = pp_keyword | loc_keyword | org_keyword
        keyword_total = dict(sorted(keyword_total.items(), reverse=True, key=lambda x: x[1]))

        # font_path = r"C:\Windows\Fonts\malgun.ttf"
        wordcloud = WordCloud(font_path='font/NanumGothic.ttf',
                              background_color='white',
                              margin=15,
                              colormap='PuBu',
                              prefer_horizontal=1,
                              min_font_size=10,
                              max_font_size=25,
                              max_words=70,
                              contour_color=None).fit_words(keyword_total)


        class SimpleGroupedColorFunc(object):
            def __init__(self, color_to_words, default_color):
                self.word_to_color = {word: color
                                      for (color, words) in color_to_words.items()
                                      for word in words}

                self.default_color = default_color

            def __call__(self, word, **kwargs):
                return self.word_to_color.get(word, self.default_color)


        color_to_words = {
            '#8fd9b6': [i for i in keyword_total.keys() if i in pp_keyword.keys()],
            '#d395d0': [i for i in keyword_total.keys() if i in loc_keyword.keys()],
            '#ff9999': [i for i in keyword_total.keys() if i in org_keyword.keys()]
        }

        default_color = '#8fd9b6'

        grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)

        # í‚¤ì›Œë“œë³„ ìƒ‰ìƒ ë³€ê²½
        wordcloud.recolor(color_func=grouped_color_func)

        # ê·¸ë˜í”„
        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        plt.show()
        st.pyplot(plt)

        annotated_text('ë²”ë¡€ : ',
            ("ì¸ë¬¼", '', "#8fd9b6"),
                       ' ',
            ("ì¥ì†Œ", '', "#d395d0"),
                       ' ',
            ("ê¸°ê´€", '', "#ff9999"),
            # ("ê¸°íƒ€ í‚¤ì›Œë“œ ", '', "#8fd9b6"),
        )


st.markdown('---')


##


## ë‰´ìŠ¤ê¸°ì‚¬
st.subheader(f':newspaper: NEWSCAN')
st.markdown(":point_down: í•´ë‹¹ ê¸°ì‚¬ë¥¼ í´ë¦­í•˜ë©´ ë¶„ì„ë‚´ìš©ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤")

# select the columns you want the users to see
gb = GridOptionsBuilder.from_dataframe(df[['ì¼ì', 'ì œëª©', 'ê¸ë¶€ì • ì—¬ë¶€', 'í”¼ì‹±ê¸°ì‚¬ ì—¬ë¶€', 'ì œëª©-ë³¸ë¬¸ ì¼ì¹˜ë„(%)',]])
# configure selection
gb.configure_selection(selection_mode="single", use_checkbox=True)
gb.configure_side_bar()
gridOptions = gb.build()

data = AgGrid(df.head(n),
              gridOptions=gridOptions,
              enable_enterprise_modules=True,
              allow_unsafe_jscode=True,
              update_mode=GridUpdateMode.SELECTION_CHANGED,
              columns_auto_size_mode=ColumnsAutoSizeMode.FIT_CONTENTS)

st.caption('-ê¸ë¶€ì • ì—¬ë¶€ : ë¶„ë¥˜ ê²°ê³¼ ê°€ì¥ ë†’ì€ í™•ë¥ (probablity)ì„ ê°€ì§„ ë¼ë²¨ê°’(ì¤‘ë¦½/ê¸ì •/ë¶€ì •)ì„ ì œì‹œ.  \n '
           '-ì œëª© ë³¸ë¬¸ ì¼ì¹˜ë„ : ì œëª©ê³¼ ë³¸ë¬¸ì˜ ì¼ì¹˜ ì •ë„ë¥¼ í¼ì„¼íŠ¸ë¡œ ì œì‹œ.  \n'
           '-í”¼ì‹±ê¸°ì‚¬ ì—¬ë¶€ : í”¼ì‹± í™•ë¥ ì´ 0.5 ì´ìƒì¸ ê²½ìš°, ğŸŸí”¼ì‹± ì˜ì‹¬.')
selected_rows = data["selected_rows"]

####
st.write("---")

####

with st.spinner('Wait for it...'):
    time.sleep(3)

###############
# ë¶„ì„ê¸°ì‚¬ ì„ íƒì‹œ
if len(selected_rows) != 0:
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(label="ê°ì„± í•„í„°", value=f"{selected_rows[0]['Senti_label']}", delta=f"{selected_rows[0]['proba']:.3f}")

    with col2:
        st.metric(label="ë³¸ë¬¸ ì¼ì¹˜ë„", value=f"{selected_rows[0]['ë³¸ë¬¸ì¼ì¹˜ë„']}", delta=f"{selected_rows[0]['Sim_score']:.3f}")

    with col3:
        st.metric(label="ë‚šì‹œê¸°ì‚¬ í•„í„°", value=f"{selected_rows[0]['ë‚šì‹œê¸°ì‚¬']}", delta=f"{selected_rows[0]['fishing_score']:.3f}")

    st.write('---')
    st.markdown(":clipboard: **ê¸°ì‚¬ìš”ì•½**")
    st.text_area(f'**ê¸°ì‚¬ ì œëª© : {selected_rows[0]["ì œëª©"]}**',
                 value = f"{str(selected_rows[0]['summary'])}",
                 label_visibility='visible',
                 height=300
                 )
    st.caption('- Gensim ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë³¸ë¬¸ì„ 300ì ì´ë‚´ë¡œ ìš”ì•½ \n '
               )



    st.write('---')

    ### ìœ ì‚¬ë„ ì¶”ì¶œ
    del tfidf, wordcloud,
    def sim(df):
        df = df.reset_index(drop=True)
        title_to_index = dict(zip(df['ì œëª©'], df.index))
        ab = ["".join(h).replace(',', ' ') for h in df.í‚¤ì›Œë“œ]

        # ë²¡í„°í™”
        tfidf = TfidfVectorizer()
        abc_tfidf_matrix = tfidf.fit_transform(ab)

        # ê¸°ì‚¬ì œëª©, ë³¸ë¬¸ë³„ Cosine ìœ ì‚¬ë„ ì‚°ì¶œ
        abc_cosine_sim = cosine_similarity(abc_tfidf_matrix, abc_tfidf_matrix)

        return title_to_index, abc_cosine_sim


    title_to_index, sim = sim(df)
    st.markdown(":printer: **ìœ ì‚¬ ê¸°ì‚¬ Recommand Top 10**")

    recom = get_recommendations(selected_rows[0]['ì œëª©'], sim)
    sim_df = pd.DataFrame(recom[0])
    sim_df = sim_df.merge(df, on='ì œëª©')[['ì œëª©','ì¼ì','ì–¸ë¡ ì‚¬','ê¸°ê³ ì', 'í”¼ì‹±ê¸°ì‚¬ ì—¬ë¶€','URL']]
    # sim_df['ìœ ì‚¬ë„'] = np.array(recom[1])[:,1]
    sim_df.reset_index(drop=True, inplace=True)
    st.dataframe(sim_df[1:],
                 use_container_width=True,
                 column_config={
                     "URL": st.column_config.LinkColumn("ì›ë¬¸ ë§í¬")
                 }
    )
    st.caption('- ì„ íƒ ê¸°ì‚¬ì™€ ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬ \n '
           '- ìœ ì‚¬ë„ ì‚°ì¶œë°©ì‹ì€ Cosin_similarity ë¥¼ ì‚¬ìš©  \n'
               )


